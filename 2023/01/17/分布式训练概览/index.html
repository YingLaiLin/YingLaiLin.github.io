<!DOCTYPE html>

<html lang="zh-CN">

<head>
    
    <title>分布式训练概览 - 土鸡莱莱的博客</title>
    <meta charset="UTF-8">
    <meta name="keywords" content="摸鱼">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
    
    

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <meta name="description" content="[TOC] 分布式训练概览定义为什么需要分布式训练？ 数据量级大（数据预处理）  工业界做模型训练的时候，需要面对千万级，亿级以上的训练数据，因此会使用 MapReduce 或者 Spark 进行数据的预处理，再采用分布式训练在成百上千的节点上进行模型训练。   大规模的数据 IO 和预处理（训练时的预处理）  工业界的数据高达千万级、亿级甚至千亿级，通常存储于分布式的存储系统中（如 HDFS">
<meta property="og:type" content="article">
<meta property="og:title" content="分布式训练概览">
<meta property="og:url" content="https://yinglailin.github.io/2023/01/17/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A6%82%E8%A7%88/index.html">
<meta property="og:site_name" content="土鸡莱莱的博客">
<meta property="og:description" content="[TOC] 分布式训练概览定义为什么需要分布式训练？ 数据量级大（数据预处理）  工业界做模型训练的时候，需要面对千万级，亿级以上的训练数据，因此会使用 MapReduce 或者 Spark 进行数据的预处理，再采用分布式训练在成百上千的节点上进行模型训练。   大规模的数据 IO 和预处理（训练时的预处理）  工业界的数据高达千万级、亿级甚至千亿级，通常存储于分布式的存储系统中（如 HDFS">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/AWoJBgKdFGWorcXuGH0GibwuP8fBMJzNg3k07WQayyoTicysricwstnOvRvEPiazyDCmx1HLJkicK7qACNYRLyFvk8Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">
<meta property="article:published_time" content="2023-01-17T01:21:46.000Z">
<meta property="article:modified_time" content="2023-01-18T15:53:30.570Z">
<meta property="article:author" content="YingLai Lin">
<meta property="article:tag" content="摸鱼">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mmbiz.qpic.cn/mmbiz_png/AWoJBgKdFGWorcXuGH0GibwuP8fBMJzNg3k07WQayyoTicysricwstnOvRvEPiazyDCmx1HLJkicK7qACNYRLyFvk8Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/combine/npm/highlight.js@9.15.8/styles/atom-one-dark.css,npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css,gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css,npm/hexo-theme-nexmoe@latest/source/lib/mdui_043tiny/css/mdui.css,npm/hexo-theme-nexmoe@latest/source/lib/iconfont/iconfont.css?v=233" crossorigin>
    <link rel="stylesheet" href="/css/style.css?v=1674530604999">
     
    
    <link rel="stylesheet" href="/lib/iconfont/iconfont.css?v=1674530604999">
    
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="mdui-drawer-body-left">
    
    <div id="nexmoe-background">
        <div class="nexmoe-bg" style="background-image: url(https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg)"></div>
        <div class="mdui-appbar mdui-shadow-0">
            <div class="mdui-toolbar">
                <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon mdui-ripple"><i class="mdui-icon nexmoefont icon-menu"></i></a>
                <div class="mdui-toolbar-spacer"></div>
                <!--<a href="javascript:;" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">search</i></a>-->
                <a href="/" title="YingLai Lin" class="mdui-btn mdui-btn-icon"><img src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/avatar.png" alt="YingLai Lin"></a>
            </div>
        </div>
    </div>
    <div id="nexmoe-header">
        <div class="nexmoe-drawer mdui-drawer" id="drawer">
    <div class="nexmoe-avatar mdui-ripple">
        <a href="/" title="YingLai Lin">
            <img src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/avatar.png" alt="YingLai Lin" alt="YingLai Lin">
        </a>
    </div>
    <div class="nexmoe-count">
        <div><span>文章</span>38</div>
        <div><span>标签</span>13</div>
        <div><span>分类</span>3</div>
    </div>
    <div class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}">
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple false" href="/" title="回到首页">
            <i class="mdui-list-item-icon nexmoefont icon-home"></i>
            <div class="mdui-list-item-content">
                回到首页
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple false" href="/about.html" title="关于博客">
            <i class="mdui-list-item-icon nexmoefont icon-info-circle"></i>
            <div class="mdui-list-item-content">
                关于博客
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple false" href="/PY.html" title="我的朋友">
            <i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i>
            <div class="mdui-list-item-content">
                我的朋友
            </div>
        </a>
        
    </div>
    <aside id="nexmoe-sidebar">
    
    <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-search">
         
            <form id="search_form" action_e="https://cn.bing.com/search?q=site:nexmoe.com" onsubmit="return search();">
                <label><input id="search_value" name="q" type="search" placeholder="搜索"></label>
            </form>
         
    </div>
</div>
    
    <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-social">
        <a class="mdui-ripple" href="https://jq.qq.com/?_wv=1027&k=5CfKHun" target="_blank" mdui-tooltip="{content: 'QQ群'}" style="color: rgb(249, 174, 8);background-color: rgba(249, 174, 8, .1);">
            <i class="nexmoefont icon-QQ"></i>
        </a><a class="mdui-ripple" href="https://space.bilibili.com/20238211" target="_blank" mdui-tooltip="{content: '哔哩哔哩'}" style="color: rgb(231, 106, 141);background-color: rgba(231, 106, 141, .15);">
            <i class="nexmoefont icon-bilibili"></i>
        </a><a class="mdui-ripple" href="https://github.com/nexmoe/" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color: rgb(25, 23, 23);background-color: rgba(25, 23, 23, .15);">
            <i class="nexmoefont icon-github"></i>
        </a>
    </div>
</div>
    
    
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">文章分类</h3>
    <div class="nexmoe-widget">

      <ul class="category-list">

        


        

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/Java-后端/">Java 后端</a>
          <span class="category-list-count">11</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/Java-后端/搜索/分布式/">分布式</a>
          <span class="category-list-count">4</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/Java-后端/搜索/">搜索</a>
          <span class="category-list-count">4</span>
        </li>

        
      </ul>

    </div>
  </div>


    
    
  <div class="nexmoe-widget-wrap">
    <div id="randomtagcloud" class="nexmoe-widget tagcloud nexmoe-rainbow">
      <a href="/tags/ES/" style="font-size: 20px;">ES</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/JVM/" style="font-size: 13.33px;">JVM</a> <a href="/tags/Java/" style="font-size: 16.67px;">Java</a> <a href="/tags/Java-Exception/" style="font-size: 10px;">Java Exception</a> <a href="/tags/Java-Method-Call/" style="font-size: 10px;">Java Method Call</a> <a href="/tags/classpath/" style="font-size: 10px;">classpath</a> <a href="/tags/github-pages/" style="font-size: 10px;">github pages</a> <a href="/tags/%E5%86%B7%E7%83%AD%E5%88%86%E7%A6%BB/" style="font-size: 13.33px;">冷热分离</a> <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" style="font-size: 13.33px;">大模型</a> <a href="/tags/%E5%B9%B6%E5%8F%91/" style="font-size: 10px;">并发</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 16.67px;">数据库</a> <a href="/tags/%E6%9E%B6%E6%9E%84%E4%BC%98%E5%8C%96/" style="font-size: 13.33px;">架构优化</a>
    </div>
    
  </div>

    
</aside>
    <div class="nexmoe-copyright">
        &copy; 2023 YingLai Lin
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        & <a href="https://github.com/theme-nexmoe/hexo-theme-nexmoe" target="_blank">Nexmoe</a>
        <br><a target="_blank" href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral"><img src="https://i.dawnlab.me/c0268c1e6cfd0863d6ba35be1575941a.png" width="150px"></a><script data-ad-client="ca-pub-2058306854838448" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    </div>
</div><!-- .nexmoe-drawer -->
    </div>
    <div id="nexmoe-content">
        <div class="nexmoe-primary">
            <div class="nexmoe-post">

  <article>
      
          <div class="nexmoe-post-cover" style="padding-bottom: 66.66666666666666%;"> 
              <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="分布式训练概览" class="lazyload">
              <h1>分布式训练概览</h1>
          </div>
      
      
      <div class="nexmoe-post-meta nexmoe-rainbow" style="margin:10px 0!important;">
    <a><i class="nexmoefont icon-calendar-fill"></i>2023年01月17日</a>
    <a><i class="nexmoefont icon-areachart"></i>2k 字</a>
    <a><i class="nexmoefont icon-time-circle-fill"></i>大概 8 分钟</a>
</div>

      

      <span id="more"></span>

<p>[TOC]</p>
<h1 id="分布式训练概览"><a href="#分布式训练概览" class="headerlink" title="分布式训练概览"></a>分布式训练概览</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="为什么需要分布式训练？"><a href="#为什么需要分布式训练？" class="headerlink" title="为什么需要分布式训练？"></a>为什么需要分布式训练？</h3><ul>
<li><p><strong>数据量级大（数据预处理）</strong></p>
<ul>
<li>工业界做模型训练的时候，需要面对千万级，亿级以上的训练数据，因此会使用 MapReduce 或者 Spark 进行数据的<strong>预处理</strong>，再采用分布式训练在成百上千的节点上进行模型训练。</li>
</ul>
</li>
<li><p><strong>大规模的数据 IO 和预处理（训练时的预处理）</strong></p>
<ul>
<li>工业界的数据高达千万级、亿级甚至千亿级，通常存储于分布式的存储系统中（如 HDFS），而读取如此大量级的数据和高效的数据预处理就变得十分棘手。离线通常采用 MapReduce、Spark、多线程/进程，或者缓存的方式进行高并发的数据读取和分布式的特征预处理。</li>
</ul>
</li>
<li><p><strong>模型参数量大</strong></p>
<ul>
<li>近期的 foundation model 参数可以达到 100B，超过了单卡的显存容量。</li>
</ul>
</li>
<li><p><strong>时效性要求高</strong></p>
<ul>
<li>尽管离线的训练对实时性要求不高，但其仍需要配合业务进行迭代。通常会通过软硬件的 scale up 和 scale out 缩短模型的训练时长。</li>
</ul>
</li>
</ul>
<h3 id="不同场景下分布式训练的痛点"><a href="#不同场景下分布式训练的痛点" class="headerlink" title="不同场景下分布式训练的痛点"></a>不同场景下分布式训练的痛点</h3><h3 id="CV-与-NLP-场景"><a href="#CV-与-NLP-场景" class="headerlink" title="CV 与 NLP 场景"></a>CV 与 NLP 场景</h3><p>在 NLP 领域， 预训练模型如 GPT-3 已经达到了 1750 亿参数，显存占用高达 2.8TB，这样的模型单卡、单机都无法容纳，因此需要采用<strong>模型并行</strong>(Model paralleism)的方式将计算图划分到不同的设备上，并构建 DAG 图进行分布式训练。</p>
<h3 id="搜广推场景"><a href="#搜广推场景" class="headerlink" title="搜广推场景"></a>搜广推场景</h3><p>不同于CV和NLP场景，在搜广推场景下，碰到的主要问题是：</p>
<ul>
<li><p><strong>模型小，词表大</strong></p>
<ul>
<li>(我们沿用XDL将模型分为DensetNet和SparseNet的描述，其中SparseNet特指Embedding Lookup Layer，主要针对给定的int或者string类ID查询相应的embedding vector；<strong>DenseNet一般是我们常说的抛开Embedding lookup Layer的模型部分</strong>）)。模型中的DenseNet部分，不像BERT是模型巨大词表小，往往一台机器的内存就可以容纳，但是其特征量级可能高达成百上千亿，造成Sparsenet部分或者Embedding lookup table高达TB级别，使得单机无法容纳。</li>
</ul>
</li>
<li><p><strong>batch 内 embedding lookup量级大，造成查询耗时大</strong></p>
<ul>
<li>由于特征数量多，一个batch可能包含几十万个ID类特征，tf 原生的embedding lookup查询耗时大，造成训练和inference性能低。尤其在线上inference的时候，无法在给定RT内完成服务响应。-</li>
</ul>
</li>
<li><p><strong>CPU集群稳定性差</strong></p>
<ul>
<li>搜广推场景数据量级大，耗费资源多，往往需要起几十个，或者成百上千个计算节点进行一次模型训练。然而GPU价格高，造成搜广推场景下，仍然主要采用CPU集群进行大规模分布式训练，然而CPU计算能力不均衡和大规模节点下通信延迟高和不稳定性上升（比如straggler 和failover问题），这会严重影响模型训练的效率和成功率。不过近些年的趋势是各大厂也在用高性能的GPU进行模型的forward和backward计算，词表的查询和参数的aggregate和update还是采用CPU进行计算。</li>
</ul>
</li>
<li><p><strong>数据具有大规模稀疏的特点</strong></p>
<ul>
<li>不同于CV和NLP场景，数据是稠密的图像和文本，搜广推的数据非常稀疏的，第一这来源于很多数据无法对所有用户和场景有效采集到，第二是因为建模使用的特征量级大造成的高维稀疏性。这会影响了数据的存储格式和计算效率。</li>
</ul>
</li>
</ul>
<p>目前各个大厂训练框架的核心主要在于两点：</p>
<ul>
<li><p><strong>分布式通信拓扑的设计</strong></p>
</li>
<li><p><strong>Embedding Lookup 的性能优化</strong></p>
</li>
</ul>
<h2 id="参数服务器（Parameter-Server"><a href="#参数服务器（Parameter-Server" class="headerlink" title="参数服务器（Parameter Server)"></a>参数服务器（Parameter Server)</h2><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h3><p>参数服务器有 <strong>parameter server</strong>和 <strong>worker</strong>两个角色，其中</p>
<ul>
<li><p><strong>parameter server</strong></p>
<ul>
<li>负责参数的存储，聚合和更新。 </li>
</ul>
</li>
<li><p><strong>worker</strong></p>
<ul>
<li><p>负责从 server pull 最新的模型参数</p>
</li>
<li><p>利用部分训练数据进行模型的 forward 和 backward 的计算得到梯度并 push 回server</p>
</li>
</ul>
</li>
</ul>
<img src="https://mmbiz.qpic.cn/mmbiz_png/AWoJBgKdFGWorcXuGH0GibwuP8fBMJzNg3k07WQayyoTicysricwstnOvRvEPiazyDCmx1HLJkicK7qACNYRLyFvk8Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" title alt="图片" width="536">

<p><strong>举个例子</strong></p>
<p>以 $F(w) = \sum^n_{i=1} l(x_i, y_i, w) + \Omega(w)$ 为例，其中 n 条数据的梯度计算是互相独立的， 因此，我们可以将单机上的训练流程拆分为如下步骤：</p>
<ul>
<li><p><strong>数据拓扑拆分</strong>：global batch size 的数据切分为的 N 个 local batch size，以将其分配到 N 个 worker 上分别进行梯度的计算。</p>
</li>
<li><p><strong>梯度计算</strong>：worker 按照一定的数据切分逻辑从数据源（如 HDFS）拉取其对应的数据，并计算梯度</p>
</li>
<li><p><strong>梯度汇聚与远端参数更新</strong>：各个 worker 将其对应的梯度 push 到参数服务器上，由其进行梯度的汇聚，并进行参数的更新</p>
</li>
<li><p><strong>本地参数更新</strong>：各个 work 从 parameter server 上 pull 最新的模型参数，并开启新一轮的训练迭代</p>
</li>
</ul>
<h3 id="参数服务器存在的问题"><a href="#参数服务器存在的问题" class="headerlink" title="参数服务器存在的问题"></a>参数服务器存在的问题</h3><h4 id="Consitency-vs-Avaiablity"><a href="#Consitency-vs-Avaiablity" class="headerlink" title="Consitency vs Avaiablity"></a>Consitency vs Avaiablity</h4><p>分布式训练中存在多个节点，也因此会因为算力或者网络情况波动导致不同节点的计算速度不一致（<strong>算力不均衡</strong>），这也因此产生了梯度的<strong>同步更新和异步更新策略</strong>：</p>
<ul>
<li><p><strong>同步更新</strong>：</p>
<ul>
<li><p>等待所有节点都计算完梯度后再进行梯度汇聚和参数更新</p>
</li>
<li><p>节点之间算力不一致导致部分节点存在空转，算力被浪费</p>
</li>
</ul>
</li>
<li><p><strong>异步更新</strong>：</p>
<ul>
<li><p>单个节点对应的梯度计算完成后就进行对应梯度的更新，无需等待所有节点计算完成。</p>
</li>
<li><p>异步更新场景下，非凸函数的收敛性没有保证，通常根据经验判定（大部分算法可以收敛、求得最优或者次优解 –&gt; 效果好就行）。</p>
</li>
</ul>
</li>
</ul>
<h4 id="All2All-的通信瓶颈"><a href="#All2All-的通信瓶颈" class="headerlink" title="All2All 的通信瓶颈"></a>All2All 的通信瓶颈</h4><p>随着 Parameter Server和 Worker的节点数增多，PS 和 worker间 ALL to ALL 的通信方式会带来新的性能瓶颈：</p>
<ul>
<li><p><strong>参数服务器数量过大</strong>: 造成一个worker pull/push时间过大；</p>
</li>
<li><p><strong>worker数量过大</strong>：造成单个PS的通信带宽瓶颈</p>
</li>
<li><p><strong>不稳定性问题</strong>: 比如训练中某个PS或者 Worker 节点突然挂了，或者出现慢节点</p>
</li>
</ul>
<h4 id="容错与弹性"><a href="#容错与弹性" class="headerlink" title="容错与弹性"></a>容错与弹性</h4><p>当 Parameter Server 或者 worker 在运行时因为各种错误（比如OOM，软硬件错误）挂了时，可以从checkpoint中 restore 参数回来进行重新训练。</p>
<hr>
<p>李沐老师基于<strong>一致性哈希</strong>将模型参数分配到各server上进行存储，通过 <strong>range pull</strong>和 <strong>range push</strong>进行参数的更新，这解决了多server的参数存储和协同计算问题（在server数量弹性变化时，尽量减少参数重新的replacement）。  – <strong>明细待看</strong></p>
<h2 id="常见并行模式"><a href="#常见并行模式" class="headerlink" title="常见并行模式"></a>常见并行模式</h2><h3 id="模型并行"><a href="#模型并行" class="headerlink" title="模型并行"></a>模型并行</h3><p>模型并行可以按其对Layer切分的维度分为Intra-layer parallelism和Inter-layer parallelism（相比于数据并行每个worker只有一部分数据，模型并行下每个node使用所有数据）：</p>
<ul>
<li><p><strong>Intra-layer parallelism（Tensor Parallelism)1</strong>，即<strong>层内划分</strong>。主要是将一层 Layer 中的矩阵计算分别拆分到不同的机器上进行运算，比如简单的Y_1=W_1 X_1这一次矩阵乘法中，我们将模型参数W_1或者输入数据X_1，按某个维度分别拆分到不同设备上计算，比如1D Megatron。</p>
</li>
<li><p><strong>Inter-layer parallelism（Pipeline Parallelism）</strong>，即<strong>层间划分</strong>。而Inter-Layer Parallism会将模型的 layers 拆分到不同的机器上，则一次forward就需要跨过不同的机器串行地进行运算，而流行并行通过将batch size切分为更小的mirco batch，减少数据依赖，从而将整个计算过程异步起来，最大化资源利用率。举例来说，在一个简单的三层MLP中（的Y_i = W_i X_i, i=1,2,3）会存在三次矩阵乘法 W_i X_i，流水线并行会把W_iX_i分别分配到三台机器上进行运算。</p>
</li>
</ul>
<h3 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h3><h3 id="流水线并行"><a href="#流水线并行" class="headerlink" title="流水线并行"></a>流水线并行</h3><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/hErbnqv49xTqjJANtL-G0Q"># 浅谈工业界分布式训练（一）</a></p>

  </article>

  
      
    <div class="nexmoe-post-copyright">
        <strong>本文作者：</strong>YingLai Lin<br>
        <strong>本文链接：</strong><a href="https://yinglailin.github.io/2023/01/17/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A6%82%E8%A7%88/" title="https:&#x2F;&#x2F;yinglailin.github.io&#x2F;2023&#x2F;01&#x2F;17&#x2F;%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A6%82%E8%A7%88&#x2F;" target="_blank" rel="noopener">https:&#x2F;&#x2F;yinglailin.github.io&#x2F;2023&#x2F;01&#x2F;17&#x2F;%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A6%82%E8%A7%88&#x2F;</a><br>
        
            <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可
        
    </div>


  
  
  <div class="nexmoe-post-meta nexmoe-rainbow">
    
    
</div>

  
      <div class="nexmoe-post-footer">
          <section class="nexmoe-comment">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.css">
<div id="gitalk"></div>
<script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script>
<script type="text/javascript">
    var gitalk = new Gitalk({
        clientID: '80b2453b6d5f37ad6225',
        clientSecret: '43e99fa852795c9a7b3eb924b2558c64b84bbdeb',
        id: window.location.pathname,
        repo: 'nexmoe.github.io',
        owner: 'nexmoe',
        admin: 'nexmoe'
    })
    gitalk.render('gitalk')
</script>
</section>
      </div>
  
</div>
            <div class="nexmoe-post-right">
              <div class="nexmoe-fixed">
                  <div class="nexmoe-tool"> 
                    
                      
                    
                      <a href="#nexmoe-content" class="toc-link" aria-label="回到顶部" title="top"><button class="mdui-fab mdui-ripple"><i class="nexmoefont icon-caret-top"></i></button></a>
                  </div>
              </div>
            </div>
        </div>
    </div>
     
    <div id="nexmoe-search-space">
        <div class="search-container">
            <div class="search-header">
                <div class="search-input-container">
                    <input class="search-input" type="text" placeholder="搜索" oninput="sinput();">
                </div>
                <a class="search-close" onclick="sclose();">×</a>
            </div>
            <div class="search-body"></div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/combine/npm/lazysizes@5.1.0/lazysizes.min.js,npm/mdui@0.4.3/dist/js/mdui.min.js?v=1"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

 

<script async src="/js/app.js?v=1674530605000"></script>



<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js"></script>
<script>
	$(".justified-gallery").justifiedGallery({
		rowHeight: 160,
		margins: 10,
	});
</script>


    





<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"left","width":200,"height":500},"mobile":{"show":true},"log":false});</script></body>

</html>
